setwd("D:\\ECML")
library(readr)
library(xgboost)
library(pROC)

banks <- read_csv('bank_info.csv')
users<-read_csv('users_2014.csv')
train <- read_csv("train_2014.csv")
train <- transform(train, CHANNEL_Br = ifelse(CHANNEL=='b', 1, 0))
train <- transform(train, CHANNEL_Pos = ifelse(CHANNEL=='p', 1, 0))
train <- transform(train, CHANNEL_Net = ifelse(CHANNEL=='n', 1, 0))
###############
# Split half years
###############
train1<-train[month(train$DATE)<7,]
train2<-train[month(train$DATE)>6,]

#################################################################
# Process 2014 training data, generate features
#################################################################
for (i in 1:nrow(users)) {
  user<-users$USER_ID[i]
  userx<-users$LOC_GEO_X[i]
  usery<-users$LOC_GEO_Y[i]
  banks$userx<-as.numeric(userx)
  banks$usery<-as.numeric(usery)
  banks$HDIST<-round(((banks$userx-banks$GEO_X)^2+(banks$usery-banks$GEO_Y)^2)^0.5/100,0)
  banks$HDISTrank<-ave(banks$HDIST, banks$userx, FUN = function(x) rank(x, ties.method = "first"))
  ##############
  # get median pos location from H1
  ##############
  DF<- subset(train1,c(train1$USER_ID==user & train1$CHANNEL_Pos==1))
  if (nrow(DF)==0) {
    banks$PDIST<-9999
    banks$PDISTrank<-9999
  } else {
    DF[nrow(DF)+1,]<-DF[nrow(DF),]
    banks$posx<-median(DF$GEO_X)
    banks$posy<-median(DF$GEO_Y)
    banks$PDIST<-round(((banks$posx-banks$GEO_X)^2+(banks$posy-banks$GEO_Y)^2)^0.5/100,0)
    banks$PDISTrank<-ave(banks$PDIST, banks$posx, FUN = function(x) rank(x, ties.method = "first"))
  }
  ###############
  # get H2 visits
  ###############
  banks$VISH1<-0
  banks$VISH2<-0
  banks$VISlast<-0
  DF<- subset(train2,c(train2$USER_ID==user & train2$CHANNEL_Br==1))
  if (nrow(DF)>0) { 
    DF <- aggregate(list(DF$CHANNEL_Br), list(DF$POI_ID),sum)
    colnames(DF)[2]<-'COUNT'
    DF<-DF[order(-DF$COUNT),]
    for (j in 1:nrow(DF)) {
      banks$VISH2[banks$POI_ID==DF[j,1]]<-DF[j,2]
    }
  }
  # get H1 visits
  DF<- subset(train1,c(train1$USER_ID==user & train1$CHANNEL_Br==1))
  # get last visited branch
  if (nrow(DF)>0) { 
    banks$VISlast[banks$POI_ID==DF$POI_ID[nrow(DF)]]<-1
    DF <- aggregate(list(DF$CHANNEL_Br), list(DF$POI_ID),sum)
    colnames(DF)[2]<-'COUNT'
    DF<-DF[order(-DF$COUNT),]
    for (j in 1:nrow(DF)) {
      banks$VISH1[banks$POI_ID==DF[j,1]]<-DF[j,2]
    }
  }
  banks$USER_ID<-user
  train_temp<-banks[banks$VISH1>0 | banks$VISH2>0 | banks$HDISTrank<6 | banks$PDISTrank<6,c('USER_ID','POI_ID','VISH2','VISH1','VISlast','PDIST','PDISTrank','HDIST','HDISTrank')]
  # pass temp dataframe to store in the 1st loop, amend it later on
  if (i==1) {
  train_store<-train_temp
  } else {
  train_store<-rbind(train_store,train_temp)
  }
}
###############
# Generate Target and derived features
###############
# Target=visitsduring anytime during the year
train_store$TARGET<-apply(train_store[,3:4],1,max,na.rm=TRUE)
# convert Target to binary 
train_store$TARGET[train_store$TARGET>0]<-1
train_store[,3:5]<-list(NULL)
# create derived features
train_store$Hcross<-train_store$HDIST*train_store$HDISTrank
train_store$Pcross<-train_store$PDIST*train_store$PDISTrank
###############
# Add user features
###############
# Swap cathegorical features
users <- transform(users, Age1 = ifelse(AGE_CAT =='a', 1, 0))
users <- transform(users, Age2 = ifelse(AGE_CAT =='b', 1, 0))
users <- transform(users, Age3 = ifelse(AGE_CAT =='c', 1, 0))
users$AGE_CAT<-NULL
users <- transform(users, CAP = ifelse(LOC_CAT =='a', 1, 0))
users <- transform(users, CIT = ifelse(LOC_CAT =='b', 1, 0))
users <- transform(users, VIL = ifelse(LOC_CAT =='c', 1, 0))
users$LOC_CAT<-NULL
users <- transform(users, INC = ifelse(INC_CAT =='d', 0, ifelse(INC_CAT =='a', 1, ifelse(INC_CAT =='b', 2, 3))))
users <- transform(users, INC0 = ifelse(INC_CAT =='d', 1, 0))
users <- transform(users, INC1 = ifelse(INC_CAT =='a', 1, 0))
users <- transform(users, INC2 = ifelse(INC_CAT =='b', 1, 0))
users <- transform(users, INC3 = ifelse(INC_CAT =='c', 1, 0))
users$INC_CAT<-NULL
users$WH<-apply(users[,18:29], 1, max)
users$Have<-users$C201401
users[,5:29]<-list(NULL)
train_store<-merge(x=train_store,y=users,by='USER_ID',all.x = TRUE)
###############
# Add location ID
train_store$LOC_ID<-1000*round(train_store$LOC_GEO_X/1000,0)+round(train_store$LOC_GEO_Y/1000,0)
###############
# Write store file 
# USER_ID POI_ID TARGET PDIST PDISTrank HDIST HDISTrank
###############
write.table(train_store,file="train_store.csv",row.names=F,sep=",")  #train_xgb


#################################################################
# Process 2015 data, generate features
#################################################################

users <- read_csv("users_2015.csv")
train <- read_csv("train_2015.csv")
train <- transform(train, CHANNEL_Br = ifelse(CHANNEL=='b', 1, 0))
train <- transform(train, CHANNEL_Pos = ifelse(CHANNEL=='p', 1, 0))
train <- transform(train, CHANNEL_Net = ifelse(CHANNEL=='n', 1, 0))
train1<-train

for (i in 1:nrow(users)) {
  user<-users$USER_ID[i]
  userx<-users$LOC_GEO_X[i]
  usery<-users$LOC_GEO_Y[i]
  banks$userx<-as.numeric(userx)
  banks$usery<-as.numeric(usery)
  banks$HDIST<-round(((banks$userx-banks$GEO_X)^2+(banks$usery-banks$GEO_Y)^2)^0.5/100,0)
  banks$HDISTrank<-ave(banks$HDIST, banks$userx, FUN = function(x) rank(x, ties.method = "first"))
  ##############
  # get median pos location from H1
  ##############
  DF<- subset(train1,c(train1$USER_ID==user & train1$CHANNEL_Pos==1))
  if (nrow(DF)==0) {
    banks$PDIST<-9999
    banks$PDISTrank<-9999
  } else {
    DF<-rbind(DF,DF[nrow(DF),])
    banks$posx<-median(as.numeric(DF$GEO_X))
    banks$posy<-median(as.numeric(DF$GEO_Y))
    banks$PDIST<-round(((banks$posx-banks$GEO_X)^2+(banks$posy-banks$GEO_Y)^2)^0.5/100,0)
    banks$PDISTrank<-ave(banks$PDIST, banks$posx, FUN = function(x) rank(x, ties.method = "first"))
  }
  banks$USER_ID<-user
  test_temp<-banks[banks$HDISTrank<6 | banks$PDISTrank<6,c('USER_ID','POI_ID','PDIST','PDISTrank','HDIST','HDISTrank')]
  
  # pass temp dataframe to store in the 1st loop, amend it later on
  if (i==1) {
  test_store<-test_temp
  } else {
  test_store<-rbind(test_store,test_temp)
  }
  
}
###############
# Generate derived features
###############
# create derived features
test_store$Hcross<-test_store$HDIST*test_store$HDISTrank
test_store$Pcross<-test_store$PDIST*test_store$PDISTrank

###############
# Add user features
###############
users <- read_csv("users_2015.csv")
# Swap cathegorical features
users <- transform(users, Age1 = ifelse(AGE_CAT =='a', 1, 0))
users <- transform(users, Age2 = ifelse(AGE_CAT =='b', 1, 0))
users <- transform(users, Age3 = ifelse(AGE_CAT =='c', 1, 0))
users$AGE_CAT<-NULL
users <- transform(users, CAP = ifelse(LOC_CAT =='a', 1, 0))
users <- transform(users, CIT = ifelse(LOC_CAT =='b', 1, 0))
users <- transform(users, VIL = ifelse(LOC_CAT =='c', 1, 0))
users$LOC_CAT<-NULL
users <- transform(users, INC = ifelse(INC_CAT =='d', 0, ifelse(INC_CAT =='a', 1, ifelse(INC_CAT =='b', 2, 3))))
users <- transform(users, INC0 = ifelse(INC_CAT =='d', 1, 0))
users <- transform(users, INC1 = ifelse(INC_CAT =='a', 1, 0))
users <- transform(users, INC2 = ifelse(INC_CAT =='b', 1, 0))
users <- transform(users, INC3 = ifelse(INC_CAT =='c', 1, 0))
users$INC_CAT<-NULL
users$WH<-apply(users[,11:16], 1, max)
users$Have<-users$C201501
users[,5:16]<-list(NULL)
test_store<-merge(x=test_store,y=users,by='USER_ID',all.x = TRUE)

###############
# Add location ID
test_store$LOC_ID<-1000*round(test_store$LOC_GEO_X/1000,0)+round(test_store$LOC_GEO_Y/1000,0)

###############
# Write store file ?????????column order
# "USER_ID","POI_ID","PDIST","PDISTrank","HDIST","HDISTrank","Hcross","Pcross",
# "GEN","LOC_GEO_X","LOC_GEO_Y","Age1","Age2","Age3","CAP","CIT","VIL","INC","INC0","INC1","INC2","INC3","WH","Have" 
write.table(test_store,file="test_store.csv",row.names=F,sep=",")

